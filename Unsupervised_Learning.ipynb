{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "X_VqEhTip1ck",
        "8zGJKyg5p1ck",
        "PVzmfK_Ep1ck",
        "ylSl6qgtp1ck",
        "ZWILFDl5p1ck",
        "M7G43BXep1ck",
        "Ag9LCva-p1cl",
        "E6MkPsBcp1cl",
        "2cELzS2fp1cl",
        "3MPXvC8up1cl",
        "UV0SzAkaZNRQ",
        "YPEH6qLeZNRQ",
        "q29F0dvdveiT",
        "EXh0U9oCveiU",
        "22aHeOlLveiV",
        "g-ATYxFrGrvw",
        "Yfr_Vlr8HBkt",
        "8yEUt7NnHlrM",
        "tEA2Xm5dHt1r",
        "I79__PHVH19G",
        "Ou-I18pAyIpj",
        "fF3858GYyt-u",
        "4_0_7-oCpUZd",
        "hwyV_J3ipUZe",
        "3yB-zSqbpUZe",
        "dEUvejAfpUZe",
        "Fd15vwWVpUZf",
        "bn_IUdTipZyH",
        "49K5P_iCpZyH",
        "Nff-vKELpZyI",
        "kLW572S8pZyI",
        "dWbDXHzopZyI",
        "yLjJCtPM0KBk",
        "xiyOF9F70UgQ",
        "7wuGOrhz0itI",
        "id1riN9m0vUs",
        "578E2V7j08f6",
        "89xtkJwZ18nB",
        "67NQN5KX2AMe",
        "Iwf50b-R2tYG",
        "GMQiZwjn3iu7",
        "WVIkgGqN3qsr",
        "XkPnILGE3zoT",
        "Hlsf0x5436Go",
        "mT9DMSJo4nBL",
        "c49ITxTc407N",
        "OeJFEK0N496M",
        "9ExmJH0g5HBk",
        "cJNqERVU536h",
        "k5UmGsbsOxih",
        "T0VqWOYE6DLQ",
        "qBMux9mC6MCf",
        "-oLEiFgy-5Pf",
        "C74aWNz2AliB",
        "2DejudWSA-a0",
        "pEMng2IbBLp7",
        "rAdphbQ9Bhjc",
        "TNVZ9zx19K6k",
        "nqoHp30x9hH9",
        "rMDnDkt2B6du",
        "yiiVWRdJDDil",
        "1UUpS68QDMuG",
        "kexQrXU-DjzY",
        "T5CmagL3EC8N",
        "BhH2vgX9EjGr",
        "qjKvONjwE8ra",
        "P1XJ9OREExlT",
        "VFOzZv6IFROw",
        "TIqpNgepFxVj",
        "VfCC591jGiD4",
        "OB4l2ZhMeS1U",
        "ArJBuiUVfxKd",
        "4qY1EAkEfxKe",
        "PiV4Ypx8fxKe",
        "TfvqoZmBfxKf",
        "dJ2tPlVmpsJ0",
        "JWYfwnehpsJ1",
        "-jK_YjpMpsJ2",
        "HAih1iBOpsJ2",
        "zVGeBEFhpsJ2",
        "bmKjuQ-FpsJ3",
        "Fze-IPXLpx6K",
        "7AN1z2sKpx6M",
        "9PIHJqyupx6M",
        "_-qAgymDpx6N",
        "Z-hykwinpx6N",
        "h_CCil-SKHpo",
        "cBFFvTBNJzUa",
        "HvGl1hHyA_VK",
        "EyNgTHvd2WFk",
        "KH5McJBi2d8v",
        "iW_Lq9qf2h6X",
        "-Kee-DAl2viO",
        "gCX9965dhzqZ",
        "gIfDvo9L0UH2"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/akeelrashid/Netflix_Movies_TV_Show_Clustering/blob/main/Unsupervised_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name**    - Netflix Movies And TV Shows Clustering\n",
        "\n"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Project Type**    - Unsupervised\n",
        "##### **Contribution**    - Individual\n",
        "##### **AKEEL RASHID**"
      ],
      "metadata": {
        "id": "beRrZCGUAJYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Summary -**"
      ],
      "metadata": {
        "id": "FJNUwmbgGyua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write the summary here within 500-600 words."
      ],
      "metadata": {
        "id": "F6v_1wHtG2nS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GitHub Link -**"
      ],
      "metadata": {
        "id": "w6K7xa23Elo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Provide your GitHub Link here."
      ],
      "metadata": {
        "id": "h1o69JH3Eqqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**\n"
      ],
      "metadata": {
        "id": "yQaldy8SH6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This dataset consists of tv shows and movies available on Netflix as of 2019. The dataset is collected from Flixable which is a third-party Netflix search engine.\n",
        "\n",
        "In 2018, they released an interesting report which shows that the number of TV shows on Netflix has nearly tripled since 2010. The streaming serviceâ€™s number of movies has decreased by more than 2,000 titles since 2010, while its number of TV shows has nearly tripled. It will be interesting to explore what all other insights can be obtained from the same dataset.\n",
        "\n",
        "Integrating this dataset with other external datasets such as IMDB ratings, rotten tomatoes can also provide many interesting findings.\n",
        "\n",
        "In this project you require to do\n",
        "1. Exploratory Data Analysis\n",
        "\n",
        "2. Understanding what type content is available in different countries\n",
        "\n",
        "3. Is Netflix has increasingly focusing on TV rather than movies in recent years.\n",
        "4. Clustering similar content by matching text-based features"
      ],
      "metadata": {
        "id": "DpeJGUA3kjGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **General Guidelines** : -  "
      ],
      "metadata": {
        "id": "mDgbUHAGgjLW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.   Well-structured, formatted, and commented code is required.\n",
        "2.   Exception Handling, Production Grade Code & Deployment Ready Code will be a plus. Those students will be awarded some additional credits.\n",
        "     \n",
        "     The additional credits will have advantages over other students during Star Student selection.\n",
        "       \n",
        "             [ Note: - Deployment Ready Code is defined as, the whole .ipynb notebook should be executable in one go\n",
        "                       without a single error logged. ]\n",
        "\n",
        "3.   Each and every logic should have proper comments.\n",
        "4. You may add as many number of charts you want. Make Sure for each and every chart the following format should be answered.\n",
        "        \n",
        "\n",
        "```\n",
        "# Chart visualization code\n",
        "```\n",
        "            \n",
        "\n",
        "*   Why did you pick the specific chart?\n",
        "*   What is/are the insight(s) found from the chart?\n",
        "* Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason.\n",
        "\n",
        "5. You have to create at least 15 logical & meaningful charts having important insights.\n",
        "\n",
        "\n",
        "[ Hints : - Do the Vizualization in  a structured way while following \"UBM\" Rule.\n",
        "\n",
        "U - Univariate Analysis,\n",
        "\n",
        "B - Bivariate Analysis (Numerical - Categorical, Numerical - Numerical, Categorical - Categorical)\n",
        "\n",
        "M - Multivariate Analysis\n",
        " ]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "6. You may add more ml algorithms for model creation. Make sure for each and every algorithm, the following format should be answered.\n",
        "\n",
        "\n",
        "*   Explain the ML Model used and it's performance using Evaluation metric Score Chart.\n",
        "\n",
        "\n",
        "*   Cross- Validation & Hyperparameter Tuning\n",
        "\n",
        "*   Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart.\n",
        "\n",
        "*   Explain each evaluation metric's indication towards business and the business impact pf the ML model used.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZrxVaUj-hHfC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Let's Begin !***"
      ],
      "metadata": {
        "id": "O_i_v8NEhb9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***1. Know Your Data***"
      ],
      "metadata": {
        "id": "HhfV-JJviCcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "Y3lxredqlCYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading"
      ],
      "metadata": {
        "id": "3RnN4peoiCZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Mount the drive with colab notebook\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "CHnpRAmgJWjn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Dataset\n",
        "data=pd.read_csv('/content/drive/MyDrive/Netflix Movie And Tv shows Project/NETFLIX MOVIES AND TV SHOWS CLUSTERING.csv')"
      ],
      "metadata": {
        "id": "4CkvbW_SlZ_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset First View"
      ],
      "metadata": {
        "id": "x71ZqKXriCWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset First Look7\n",
        "data.head()"
      ],
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "7hBIi_osiCS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Rows & Columns count\n",
        "print(f'Shape of given Dataset is {data.shape}')\n",
        "print(f'Dataset contains {data.shape[0]} Rows and {data.shape[1]} Columns')"
      ],
      "metadata": {
        "id": "Kllu7SJgmLij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Information"
      ],
      "metadata": {
        "id": "JlHwYmJAmNHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Info\n",
        "data.info()"
      ],
      "metadata": {
        "id": "e9hRXRi6meOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Points to be notes**:\n",
        "* Dataset contain only one **int** column i,e **release_year**\n",
        "* There are many columns which contain **null** values"
      ],
      "metadata": {
        "id": "mEV3MubRKdRK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Duplicate Values"
      ],
      "metadata": {
        "id": "35m5QtbWiB9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Duplicate Value Count\n",
        "data.duplicated().any()"
      ],
      "metadata": {
        "id": "1sLdpKYkmox0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**`Our dataset doesn't contain any duplicated value`**"
      ],
      "metadata": {
        "id": "5Y053sQhlVoQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Missing Values/Null Values"
      ],
      "metadata": {
        "id": "PoPl-ycgm1ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing Values/Null Values Count\n",
        "print('Missing Value Count')\n",
        "print('-'*40)\n",
        "print(data.isnull().sum().sort_values(ascending=False))\n",
        "print('-'*40)\n",
        "print('Missing Value Percentage')\n",
        "print('-'*40)\n",
        "print(round((data.isnull().sum().sort_values(ascending=False))*100/len(data),2))"
      ],
      "metadata": {
        "id": "GgHWkxvamxVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " **director** feature has maximum null vlaue **30.68%**,followed by **cast**,**country**,**date_added**,**rating**."
      ],
      "metadata": {
        "id": "I5j0bH3haPcu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the missing values\n",
        "sns.heatmap(data.isnull(),cbar=False,yticklabels=False)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3q5wnI3om9sJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What did you know about your dataset?"
      ],
      "metadata": {
        "id": "H0kj-8xxnORC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I have been given a dataset which consists of Tv shows and Movies available on netflix as of 2019.The dataset consists of **7787** rows and **12** features.The dataset **doesn't** contain any **duplicated** values but there are many features in dataset which **contains null** values like  **director** feature has maximum null vlaue around **30.68%**,followed by **cast 9.22%** ,**country 6.51%**,**date_added 0.13%** and **rating 0.09%**.\n",
        "\n",
        "The dataset provides us information regarding Tv shows or Movies that has been added on Netflix.It provides information like unique Show_id,Title,Director,cast of the Tv show/Movie and Country where Movie/Tv show was produced.When was it added on Netflix,what is the release date,duration,Category,rating and Description of Movie/Tv Show.\n",
        "\n",
        " My task is to **explore** the data in order to find some useful insights.Try to understand what type of **content** is available in **different countries** and has to develop a **Clustering model** based on matching text-based Feature"
      ],
      "metadata": {
        "id": "gfoNAAC-nUe_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***2. Understanding Your Variables***"
      ],
      "metadata": {
        "id": "nA9Y7ga8ng1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Columns\n",
        "data.columns"
      ],
      "metadata": {
        "id": "j7xfkqrt5Ag5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Describe\n",
        "data.describe(include='all')"
      ],
      "metadata": {
        "id": "DnOaZdaE5Q5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Variables Description"
      ],
      "metadata": {
        "id": "PBTbrJXOngz2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here is the description of all Features:\n",
        "\n",
        "**show_id**: Unique id for each Movie/show.\n",
        "\n",
        "**type**: Identifier a Movie/TV Show\n",
        "\n",
        "**title**: Name of the Movie/TV show.\n",
        "\n",
        "**director**: Name of the director of the Movie/TV show.\n",
        "\n",
        "**cast**: Names of the actors and actresses involved in the Movie/TV show.\n",
        "\n",
        "**country**: Country where Movie/Show was produced.\n",
        "\n",
        "**date_added**: When was the Movie/Show added to Netflix.\n",
        "\n",
        "**release_year**: Which year Movie/Show was released.\n",
        "\n",
        "**rating**: TV rating of the show.\n",
        "\n",
        "**duration**: Total duration in minutes or Number of seasons\n",
        "\n",
        "**listed_in**: Categories or genres of the Movie/TV show.\n",
        "\n",
        "**description**: A brief summary of Movie/Tv show"
      ],
      "metadata": {
        "id": "aJV4KIxSnxay"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check Unique Values for each variable."
      ],
      "metadata": {
        "id": "u3PMJOP6ngxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Unique Values for each variable.\n",
        "print(data.apply(lambda col:col.unique()))\n",
        "print('-'*50)\n",
        "print('Unique Value Count')\n",
        "print('-'*50)\n",
        "print(data.apply(lambda col:col.nunique()))"
      ],
      "metadata": {
        "id": "zms12Yq5n-jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. ***Data Wrangling***"
      ],
      "metadata": {
        "id": "dauF4eBmngu3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Wrangling Code"
      ],
      "metadata": {
        "id": "bKJF3rekwFvQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Null Value Treatment**"
      ],
      "metadata": {
        "id": "tYGOEYkxBeO5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Get null columns\n",
        "null_columns=data.columns[data.isnull().any()]\n",
        "print('Columns contain null values are :',null_columns.to_list())\n",
        "print('-'*50)\n",
        "#Get Null value Count\n",
        "print('Null value Count of each Column \\n',data[null_columns].isnull().sum().sort_values(ascending=False))\n",
        "print('-'*50)\n",
        "#null value percentage\n",
        "print('Null Value Percentage of each Column\\n',round((data[null_columns].isnull().sum().sort_values(ascending=False))*100/len(data),2))"
      ],
      "metadata": {
        "id": "sXpdHrIKFkyd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Value Counts of Each Null Column\n",
        "for col in null_columns:\n",
        "  print('-'*50)\n",
        "  print('\\033[1m' + col,'Column'+ '\\033[0m')\n",
        "  print('-'*50)\n",
        "  print(data[col].value_counts())"
      ],
      "metadata": {
        "id": "CcUL3QvhMi5y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Filling null values present in **director and cast** column with **unknown** as i don't have any knowledge or data about these features\n",
        "* We can see from the value_counts that most of Movies/Shows are from **US** so,let's fill missing values in **Country** Column with **Mode**\n",
        "* Column like **date_added,country** contain **few** null value so, these values can be **droped**\n"
      ],
      "metadata": {
        "id": "c2QaJZgzHz_J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#droping/filling null values\n",
        "data[['director','cast']]=data[['director','cast']].fillna('unknown')\n",
        "data['country']=data['country'].fillna(data['country'].mode()[0])\n",
        "data.dropna(axis=0,inplace=True)"
      ],
      "metadata": {
        "id": "_wmktwpVFN9j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#visualizing the data again after dealing with the null values\n",
        "sns.heatmap(data.isnull(),cbar=False,yticklabels=False)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ePwLWOMsFNph"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "id": "fflo0yDIFM6w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "data['date_added']=pd.to_datetime(data['date_added'])\n",
        "data['added_year']=data['date_added'].dt.year\n",
        "data['added_month']=data['date_added'].dt.month\n",
        "data['added_day']=data['date_added'].dt.day\n"
      ],
      "metadata": {
        "id": "whGpkvOWDzWd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "id": "oEVMh0-iP3F6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#exploring rating feature\n",
        "data['rating'].unique()"
      ],
      "metadata": {
        "id": "qq-a02cSnmzU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exploring Rating Column:\n",
        "* TV-MA :- Mature Audience Only (for adults and may be unsuitable for children under 17)\n",
        "* R :- Restricted (for adults and may be unsuitable for children under 17)\n",
        "* PG-13 :-Parents Strongly Cautioned (Some material may not be suited for children under age 13.)\n",
        "* TV-14 :- for children ages 14 and older\n",
        "* TV-PG :- Parental Guidance Suggested\n",
        "* NR :- Not rated (can be considered for adults)\n",
        "* TV-G :- General Audience (for all ages)\n",
        "* TV-Y :- Content for children ages 2 to 6\n",
        "* TV-Y7 :- Content for children ages 7 and older (older children)\n",
        "* PG :- Parental Guidance Suggested\n",
        "* G :-General Audience (for all ages)\n",
        "* NC-17 :- Clearly Adult\n",
        "* TV-Y7-FV :- Content for children ages 7 and older (older children)\n",
        "* UR :- Unrated (can be considered for adults)\n",
        "\n",
        "convert the result into bins:\n",
        "  *  **Adult** (17+): TV-MA, R ,NC-17,NR,UR\n",
        "  *  **Children**: TV-PG, TV-G,TV-Y,TV-Y7,TV-Y7-FV\n",
        "  *  **Teenagers**: PG-13, TV-14\n",
        "  *  **General Audience**: PG,G\n",
        "\n"
      ],
      "metadata": {
        "id": "tzNHgVUVnyhG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#define age_group and map it with rating\n",
        "age_groups = {'TV-MA': 'Adults',\n",
        "              'R': 'Adults',\n",
        "              'PG-13': 'Teenagers',\n",
        "              'TV-14': 'Teenagers',\n",
        "              'TV-PG': 'Children',\n",
        "              'NR': 'Adults',\n",
        "              'TV-G': 'Children',\n",
        "              'TV-Y': 'Children',\n",
        "              'TV-Y7': 'Children',\n",
        "              'PG': 'General Audience',\n",
        "              'G': 'General Audience',\n",
        "              'NC-17': 'Adults',\n",
        "              'TV-Y7-FV': 'Children',\n",
        "              'UR': 'Adults'}\n",
        "data['age_group'] = data['rating'].map(age_groups)"
      ],
      "metadata": {
        "id": "uvvCDM6arICe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['duration'].unique()"
      ],
      "metadata": {
        "id": "AE75WqTQANdc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#removing season,min,seasons,s from duration\n",
        "data['duration'] = data['duration'].str.replace('Season', '').str.replace('Seasons', '').str.replace('min', '').str.replace('s','')\n",
        "data['duration']=data['duration'].astype(int)"
      ],
      "metadata": {
        "id": "FLKU_7_ooREu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As the duration column contains season,seasons,s,min at end so,it will be difficult it do EDA on it."
      ],
      "metadata": {
        "id": "6ox4VlBeBzXv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create movies and show dataframe\n",
        "movies=data[data['type']=='Movie']\n",
        "shows=data[data['type']=='TV Show']"
      ],
      "metadata": {
        "id": "0-l2l95RxA5o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "s5TNoqONyRUD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What all manipulations have you done and insights you found?"
      ],
      "metadata": {
        "id": "MSa1f5Uengrz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "LbyXE7I1olp8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***4. Data Vizualization, Storytelling & Experimenting with charts : Understand the relationships between variables***"
      ],
      "metadata": {
        "id": "GF8Ens_Soomf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 1 Distribution of Content Type"
      ],
      "metadata": {
        "id": "0wOQAZs5pc--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 1 visualization code\n",
        "#univerate analysis\n",
        "data['type'].value_counts().plot(kind='pie',autopct='%1.1f%%',shadow=True,explode=[0,0.1])\n",
        "plt.title('Distribution of Content Types')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7v_ESjsspbW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "K5QZ13OEpz2H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I have plotted **pie** chart to find out the distribution of **Tv Show** and **Movie** in the dataset"
      ],
      "metadata": {
        "id": "XESiWehPqBRc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "lQ7QKXXCp7Bj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the plot it can be seen that **Movie** content is more **69.1** and **Tv show** content is less **30.9**  in the dataset"
      ],
      "metadata": {
        "id": "C_j1G7yiqdRP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "448CDAPjqfQr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are less Tv show content so it is recomended to increase the TV show content"
      ],
      "metadata": {
        "id": "3cspy4FjqxJW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 2 Content Distribution among Age Groups"
      ],
      "metadata": {
        "id": "KSlN3yHqYklG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 2 visualization code\n",
        "#univeriate analysis\n",
        "\n",
        "# Plot pie chart for the entire dataset\n",
        "data['age_group'].value_counts().plot(kind='pie', autopct='%1.1f%%', shadow=True)\n",
        "plt.title('Age Group Distribution (Overall)')\n",
        "plt.show()\n",
        "\n",
        "# Plot pie chart for movies\n",
        "movies['age_group'].value_counts().plot(kind='pie', autopct='%1.1f%%', shadow=True)\n",
        "plt.title('Age Group Distribution (Movies)')\n",
        "plt.show()\n",
        "\n",
        "# Plot pie chart for TV shows\n",
        "shows['age_group'].value_counts().plot(kind='pie', autopct='%1.1f%%', shadow=True)\n",
        "plt.title('Age Group Distribution (TV Shows)')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "R4YgtaqtYklH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t6dVpIINYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I have plotted pie chart to find out the distribution among different age group"
      ],
      "metadata": {
        "id": "5aaW0BYyYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ijmpgYnKYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "it can be analysed from the pie chart that most of the content in the Netflix is suitable for **Adults** and **Teenagers** and also in TV Show there is no content for **General Audience**"
      ],
      "metadata": {
        "id": "PSx9atu2YklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "-JiQyfWJYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For gaining high revenue production company should focus more on Adult and Teenagers content"
      ],
      "metadata": {
        "id": "BcBbebzrYklV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 3 Duration Distribution"
      ],
      "metadata": {
        "id": "EM7whBJCYoAo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 3 visualization code\n",
        "#univeriate Analysis\n",
        "\n",
        "#Plotting distplot for Movie duration\n",
        "sns.set_style('darkgrid')\n",
        "plt.figure(figsize=(10,7))\n",
        "sns.distplot(movies['duration'],color='black')\n",
        "plt.title('Distribution of Movie Durations')\n",
        "plt.xlabel('Duration in minutes')\n",
        "plt.show()\n",
        "\n",
        "#Plotting Count plot for Shows duration\n",
        "plt.figure(figsize=(10,7))\n",
        "ax = sns.countplot(data=shows, x='duration')\n",
        "for p in ax.patches:\n",
        "    ax.annotate(format(p.get_height(), '.0f'), (p.get_x() + p.get_width() / 2., p.get_height()), ha='center', va='center', xytext=(0, 5), textcoords='offset points')\n",
        "plt.xlabel('Duration in Season')\n",
        "plt.ylabel('Count')\n",
        "plt.title('Distribution of TV Show Durations')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "t6GMdE67YoAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "fge-S5ZAYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I have plotted distplot and count plot to find out the duration distribution in movies and TV shows"
      ],
      "metadata": {
        "id": "5dBItgRVYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "85gYPyotYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "It can be seen that most of the movies has duration of around **90 to 140 minutes** and most of the TV shows has only **1 Season**."
      ],
      "metadata": {
        "id": "4jstXR6OYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 4 Content Added to Netflix OverTime"
      ],
      "metadata": {
        "id": "4Of9eVA-YrdM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 4 visualization code\n",
        "movie_content=movies.groupby(['added_year','added_month']).size().reset_index(name='count')\n",
        "show_content=shows.groupby(['added_year','added_month']).size().reset_index(name='count')\n",
        "#plotting line chart\n",
        "sns.set_style('darkgrid')\n",
        "plt.figure(figsize=(15, 6))\n",
        "plt.plot(show_content.index, show_content['count'], marker='o',color='black',label='Tv Show')\n",
        "plt.xlabel('Timeline')\n",
        "plt.ylabel('Number of Content Added')\n",
        "plt.title('TV Content Added to Netflix Over Time')\n",
        "plt.xticks(show_content.index, show_content.apply(lambda x: f'{x[\"added_year\"]}-{x[\"added_month\"]:02}', axis=1), rotation='vertical')\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "#ploting month-wise\n",
        "sns.set_style('darkgrid')\n",
        "plt.figure(figsize=(15, 6))\n",
        "plt.plot(movie_content.index, movie_content['count'], marker='o',label='Movies')\n",
        "plt.xlabel('Timeline')\n",
        "plt.ylabel('Number of Content Added')\n",
        "plt.title('Movie Content Added to Netflix Over Time')\n",
        "plt.xticks(movie_content.index, movie_content.apply(lambda x: f'{x[\"added_year\"]}-{x[\"added_month\"]:02}', axis=1), rotation='vertical')\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "irlUoxc8YrdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "iky9q4vBYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I have plotted a line plot to find find out the content added on netflix overtime"
      ],
      "metadata": {
        "id": "aJRCwT6DYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "F6T5p64dYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* It can be seen that after **2015** large number of Tv Showa were added on the platform.In **Nov 2019** maximum Tv show content was added to the platform.\n",
        "* Similarly after **2015** large number of Movie content was added to the platform and in  **Nov 2019** maximum content was added."
      ],
      "metadata": {
        "id": "Xx8WAJvtYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 5 Content Added to Netflix by Day of Month"
      ],
      "metadata": {
        "id": "bamQiAODYuh1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 5 visualization code\n",
        "plt.figure(figsize=(14, 6))\n",
        "ax = sns.countplot(data=movies, x='added_day', color='r', label='Movie')\n",
        "for p in ax.patches:\n",
        "    ax.annotate(format(p.get_height(), '.0f'), (p.get_x() + p.get_width() / 2., p.get_height()),\n",
        "                ha = 'center', va = 'center', xytext = (0, 5), textcoords = 'offset points')\n",
        "ax = sns.countplot(data=shows, x='added_day', color='b', label='Show')\n",
        "for p in ax.patches:\n",
        "    ax.annotate(format(p.get_height(), '.0f'), (p.get_x() + p.get_width() / 2., p.get_height()),\n",
        "                ha = 'center', va = 'center', xytext = (0, 5), textcoords = 'offset points')\n",
        "\n",
        "plt.legend()\n",
        "plt.xlabel('Day of the Month')\n",
        "plt.ylabel('Count')\n",
        "plt.title('Content Added to Netflix by Day of the Month')\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "ym5E_-eG9e58"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "QHF8YVU7Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I have plotted count plot to find distribution of content added by Day of Month"
      ],
      "metadata": {
        "id": "dcxuIMRPYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "GwzvFGzlYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "It can be find out that on **1st** of every month both Tv show and Movie maximum content has been added to the platform"
      ],
      "metadata": {
        "id": "uyqkiB8YYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "qYpmQ266Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "New content should be added to platform at regular interval"
      ],
      "metadata": {
        "id": "_WtzZ_hCYuh4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 6 Content Release Count by Year"
      ],
      "metadata": {
        "id": "OH-pJp9IphqM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 6 visualization code\n",
        "plt.figure(figsize=(14,5))\n",
        "release_count = data.groupby('release_year').size().reset_index(name='count')\n",
        "movies_count = movies.groupby('release_year').size().reset_index(name='count')\n",
        "show_count = shows.groupby('release_year').size().reset_index(name='count')\n",
        "plt.plot(movies_count['release_year'], movies_count['count'], color='green',marker='o',label='Movie Release')\n",
        "plt.plot(show_count['release_year'], show_count['count'], color='black',marker='*',label='TV Show Release')\n",
        "plt.xticks(release_count['release_year'], rotation='vertical')\n",
        "plt.xlabel('Release Year')\n",
        "plt.ylabel('Count')\n",
        "plt.title('Content Release Count by Year')\n",
        "plt.tight_layout()\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "sNlh2vP0hzFM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "bbFf2-_FphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I have used line plot to find the distribution of release of Movies and TV shows by year"
      ],
      "metadata": {
        "id": "loh7H2nzphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "_ouA3fa0phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "It can be seen that after **2008** more number of movies and TV shows were released and it can be also seen that after **2019** there were large drop in release may be because of covid"
      ],
      "metadata": {
        "id": "VECbqPI7phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 7 Top Genres"
      ],
      "metadata": {
        "id": "PIIx-8_IphqN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "top_genres=data['listed_in'].str.split(',',expand=True).stack().str.strip().value_counts().head(15)\n",
        "top_movie_genres = movies['listed_in'].str.split(',', expand=True).stack().str.strip().value_counts().head(15)\n",
        "top_show_genres=shows['listed_in'].str.split(',',expand=True).stack().str.strip().value_counts().head(15)\n"
      ],
      "metadata": {
        "id": "vHbf6Elr5s-W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 7 visualization code\n",
        "# Plot the top genres for overall data\n",
        "plt.figure(figsize=(12, 6))\n",
        "ax=top_genres.plot(kind='bar', color='purple')\n",
        "plt.xlabel('Genre')\n",
        "plt.ylabel('Count')\n",
        "plt.title('Top 15 Genres in Overall Data')\n",
        "plt.xticks(rotation='vertical')\n",
        "plt.tight_layout()\n",
        "for p in ax.patches:\n",
        "    ax.annotate(format(p.get_height(), '.0f'), (p.get_x() + p.get_width() / 2., p.get_height()), ha='center', va='center', xytext=(0, 5), textcoords='offset points')\n",
        "plt.show()\n",
        "\n",
        "# Plot the top genres for movies\n",
        "plt.figure(figsize=(12, 6))\n",
        "ax=top_movie_genres.plot(kind='bar', color='blue')\n",
        "plt.xlabel('Genre')\n",
        "plt.ylabel('Count')\n",
        "plt.title('Top 15 Genres in Movies')\n",
        "plt.xticks(rotation='vertical')\n",
        "plt.tight_layout()\n",
        "for p in ax.patches:\n",
        "    ax.annotate(format(p.get_height(), '.0f'), (p.get_x() + p.get_width() / 2., p.get_height()), ha='center', va='center', xytext=(0, 5), textcoords='offset points')\n",
        "plt.show()\n",
        "\n",
        "# Plot the top genres for TV shows\n",
        "plt.figure(figsize=(12, 6))\n",
        "ax=top_show_genres.plot(kind='bar', color='green')\n",
        "plt.xlabel('Genre')\n",
        "plt.ylabel('Count')\n",
        "plt.title('Top 15 Genres in TV Shows')\n",
        "plt.xticks(rotation='vertical')\n",
        "plt.tight_layout()\n",
        "for p in ax.patches:\n",
        "    ax.annotate(format(p.get_height(), '.0f'), (p.get_x() + p.get_width() / 2., p.get_height()), ha='center', va='center', xytext=(0, 5), textcoords='offset points')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "5DnpmH833I28"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t27r6nlMphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I have plotted barplot to find out the Top 15 genres"
      ],
      "metadata": {
        "id": "iv6ro40sphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "r2jJGEOYphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "It can be seen that **Internation Movies and TV shows** are most popular genres in Tv show and Movies followed by **Dramas** and **Comedy**"
      ],
      "metadata": {
        "id": "Po6ZPi4hphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 8 Top 15 Countries"
      ],
      "metadata": {
        "id": "BZR9WyysphqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 8 visualization code\n",
        "top_country=data['country'].str.split(',',expand=True).stack().str.strip().value_counts().head(15)\n",
        "movie_country=movies['country'].str.split(',',expand=True).stack().str.strip().value_counts().head(15)\n",
        "show_country=shows['country'].str.split(',',expand=True).stack().str.strip().value_counts().head(15)\n",
        "#Plot the top 15 Producing Countries for overall data\n",
        "plt.figure(figsize=(10,5))\n",
        "ax=top_country.plot(kind='bar',color='blue')\n",
        "plt.xlabel('Country')\n",
        "plt.ylabel('Count')\n",
        "plt.title('Top 15 Content Producing Countries')\n",
        "plt.xticks(rotation='vertical')\n",
        "plt.tight_layout()\n",
        "for p in ax.patches:\n",
        "    ax.annotate(format(p.get_height(), '.0f'), (p.get_x() + p.get_width() / 2., p.get_height()), ha='center', va='center', xytext=(0, 5), textcoords='offset points')\n",
        "plt.show()\n",
        "#Plot the top 15 Movie Producing Countries\n",
        "plt.figure(figsize=(10,5))\n",
        "ax=movie_country.plot(kind='bar',color='blue')\n",
        "plt.xlabel('Country')\n",
        "plt.ylabel('Count')\n",
        "plt.title('Top 15 Movie Producing Countries')\n",
        "plt.xticks(rotation='vertical')\n",
        "plt.tight_layout()\n",
        "for p in ax.patches:\n",
        "    ax.annotate(format(p.get_height(), '.0f'), (p.get_x() + p.get_width() / 2., p.get_height()), ha='center', va='center', xytext=(0, 5), textcoords='offset points')\n",
        "plt.show()\n",
        "#Plot the top 15 TV Shows Producing Countries\n",
        "plt.figure(figsize=(10,5))\n",
        "ax=show_country.plot(kind='bar',color='blue')\n",
        "plt.xlabel('Country')\n",
        "plt.ylabel('Count')\n",
        "plt.title('Top 15 TV Shows Producing Countries')\n",
        "plt.xticks(rotation='vertical')\n",
        "plt.tight_layout()\n",
        "for p in ax.patches:\n",
        "    ax.annotate(format(p.get_height(), '.0f'), (p.get_x() + p.get_width() / 2., p.get_height()), ha='center', va='center', xytext=(0, 5), textcoords='offset points')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "LtlfCuYMEg0J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "jj7wYXLtphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I have plotted bar plot to find out what are the top content producing Countries"
      ],
      "metadata": {
        "id": "Ob8u6rCTphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "eZrbJ2SmphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the graph it can be analysed that:\n",
        "* **USA** is the top content Producing Country followed by **India** and **United Kingdom** in genreal and also in **Movies** related Content\n",
        "* **USA** also produces more **TV series** followed by **United Kingdom**,**japan**\n",
        "* **India** produces more **Movies** than **TV Shows**"
      ],
      "metadata": {
        "id": "mZtgC_hjphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "rFu4xreNphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Countries can focus also on producing more and more TV shows along with Movies"
      ],
      "metadata": {
        "id": "ey_0qi68phqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 9 Top Show/Movie Director"
      ],
      "metadata": {
        "id": "YJ55k-q6phqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 9 visualization code\n",
        "# Generate the word cloud for Top Movie director\n",
        "movie_director=movies[movies['director']!='unknown'].reset_index()\n",
        "top_movie_director=movie_director['director'].str.split(',',expand=True).stack().str.strip().value_counts().head(10)\n",
        "\n",
        "from wordcloud import WordCloud\n",
        "wordcloud = WordCloud(background_color='white', colormap='cool', width=800, height=400)\n",
        "wordcloud.generate_from_frequencies(top_movie_director)\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.imshow(wordcloud, interpolation='bilinear')\n",
        "plt.axis('off')\n",
        "plt.title('Top Movie Director Directors')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "LGKrdzy6dhQq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate the word cloud  for Top Show director\n",
        "show_director=shows[shows['director']!='unknown'].reset_index()\n",
        "top_show_director=show_director['director'].str.split(',',expand=True).stack().str.strip().value_counts().head(10)\n",
        "\n",
        "wordcloud = WordCloud(background_color='white', colormap='Paired', width=800, height=400)\n",
        "wordcloud.generate_from_frequencies(top_show_director)\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.imshow(wordcloud, interpolation='bilinear')\n",
        "plt.axis('off')\n",
        "plt.title('Top TV Show Directors')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "LhIndUNcvRt8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "gCFgpxoyphqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I have plotted word cloud to visualize top Tv show/Movie Director"
      ],
      "metadata": {
        "id": "TVxDimi2phqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "OVtJsKN_phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the Wordcloud graph it can be seen that\n",
        "* **Jan Suter** followed by **Raul Campos,Jay Karas** has directed maximum Movies\n",
        "* **Alastair Fothergill** and **Ken Burns** has directed maximum TV Shows"
      ],
      "metadata": {
        "id": "ngGi97qjphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 10 Most Popular Cast"
      ],
      "metadata": {
        "id": "U2RJ9gkRphqQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 10 visualization code\n",
        "movie_cast=movies[movies['cast']!='unknown']['cast'].str.split(',',expand=True).stack().str.strip().value_counts().head(10)\n",
        "#plot world Cloud for Most Popular Movie cast\n",
        "from wordcloud import WordCloud\n",
        "wordcloud = WordCloud(background_color='white', colormap='cool', width=800, height=400)\n",
        "wordcloud.generate_from_frequencies(movie_cast)\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.imshow(wordcloud, interpolation='bilinear')\n",
        "plt.axis('off')\n",
        "plt.title('Most Popular Movie Cast')\n",
        "plt.show()\n",
        "#plot world Cloud for Most Popular TV show cast\n",
        "show_cast=shows[shows['cast']!='unknown']['cast'].str.split(',',expand=True).stack().str.strip().value_counts().head(10)\n",
        "wordcloud = WordCloud(background_color='white', colormap='viridis', width=800, height=400)\n",
        "wordcloud.generate_from_frequencies(show_cast)\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.imshow(wordcloud, interpolation='bilinear')\n",
        "plt.axis('off')\n",
        "plt.title('Most Popular TV Show Cast')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "8bL3cQLoyUXW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "1M8mcRywphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I have plotted Word Cloud to find Most Popular cast"
      ],
      "metadata": {
        "id": "8agQvks0phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "tgIPom80phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "It can be seen that:   \n",
        "* **Anupam Kher**,**Shah Rukh Khan**,**Naseeruddin Shah** etc are famous Movie Cast\n",
        "*  **Takahiro Sakurai, Yuki Kaji,Daisuke Ono** etc are famous TV Show cast"
      ],
      "metadata": {
        "id": "Qp13pnNzphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 11 Distribution of Content Produced by Top Countries for different Age Group"
      ],
      "metadata": {
        "id": "x-EpHcCOp1ci"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 11 visualization code\n",
        "# Select the top N countries based on content creation\n",
        "top_countries = data['country'].str.split(',', expand=True).stack().str.strip().value_counts().head(10).index\n",
        "\n",
        "# Filter the data for the top countries\n",
        "filtered_data = data[data['country'].isin(top_countries)]\n",
        "\n",
        "# Create a countplot to visualize the distribution of age groups in each top country\n",
        "plt.figure(figsize=(15, 6))\n",
        "sns.countplot(data=filtered_data, x='country', hue='age_group', palette='Set2')\n",
        "plt.xlabel('Country')\n",
        "plt.ylabel('Count')\n",
        "plt.legend(title='Age Group')\n",
        "plt.title('Distribution of Content Produced by Top Countries for different Age Group')\n",
        "plt.xticks(rotation='vertical')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "mAQTIvtqp1cj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "X_VqEhTip1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "using countplot to find find out the distribution of content produced by top countries for different age groups"
      ],
      "metadata": {
        "id": "-vsMzt_np1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "8zGJKyg5p1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "It was found that:\n",
        "* Almost **all top countries** produced more **adult** related content except **india**, they produce more **Teenagers** content"
      ],
      "metadata": {
        "id": "ZYdMsrqVp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 12 Frequently Word Used in Description"
      ],
      "metadata": {
        "id": "n3dbpmDWp1ck"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 12 visualization code\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from wordcloud import WordCloud\n",
        "\n",
        "# Download the stopwords corpus\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Define the list of stop words\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "# Combine the descriptions into a single string\n",
        "combined_description = ' '.join(data['description'])\n",
        "\n",
        "# Remove stop words from the combined description\n",
        "filtered_description = ' '.join(word for word in combined_description.split() if word.lower() not in stop_words)\n",
        "\n",
        "# Generate the word cloud from the filtered description\n",
        "wordcloud = WordCloud(background_color='white', colormap='viridis', width=800, height=400)\n",
        "wordcloud.generate(filtered_description)\n",
        "\n",
        "# Plot the word cloud\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.imshow(wordcloud, interpolation='bilinear')\n",
        "plt.axis('off')\n",
        "plt.title('Word Cloud of Descriptions (Without Stop Words)')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "bwevp1tKp1ck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "ylSl6qgtp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using World Cloud to find out what are the most frequent word used in descripition"
      ],
      "metadata": {
        "id": "m2xqNkiQp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ZWILFDl5p1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "It can be seen that word like **family,friend,life,find,two take,worldwoman,woman,live,love** etc are most frequent words used in the description"
      ],
      "metadata": {
        "id": "x-lUsV2mp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***5. Hypothesis Testing***"
      ],
      "metadata": {
        "id": "g-ATYxFrGrvw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Based on your chart experiments, define three hypothetical statements from the dataset. In the next three questions, perform hypothesis testing to obtain final conclusion about the statements through your code and statistical testing."
      ],
      "metadata": {
        "id": "Yfr_Vlr8HBkt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "-7MS06SUHkB-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 1"
      ],
      "metadata": {
        "id": "8yEUt7NnHlrM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "tEA2Xm5dHt1r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "HI9ZP0laH0D-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "I79__PHVH19G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value"
      ],
      "metadata": {
        "id": "oZrfquKtyian"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "Ou-I18pAyIpj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "s2U0kk00ygSB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "fF3858GYyt-u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "HO4K0gP5y3B4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 2"
      ],
      "metadata": {
        "id": "4_0_7-oCpUZd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "hwyV_J3ipUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "FnpLGJ-4pUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "3yB-zSqbpUZe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value"
      ],
      "metadata": {
        "id": "sWxdNTXNpUZe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "dEUvejAfpUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "oLDrPz7HpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "Fd15vwWVpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "4xOGYyiBpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 3"
      ],
      "metadata": {
        "id": "bn_IUdTipZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "49K5P_iCpZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "7gWI5rT9pZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "Nff-vKELpZyI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value"
      ],
      "metadata": {
        "id": "s6AnJQjtpZyI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "kLW572S8pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "ytWJ8v15pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "dWbDXHzopZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "M99G98V6pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***6. Feature Engineering & Data Pre-processing***"
      ],
      "metadata": {
        "id": "yLjJCtPM0KBk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Handling Missing Values"
      ],
      "metadata": {
        "id": "xiyOF9F70UgQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#let's first create a copy of dataset\n",
        "df=data.copy()"
      ],
      "metadata": {
        "id": "OZsI9Hrfto1V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#let's drop some unwanted features from dataset\n",
        "df.drop(columns=['show_id','date_added'],axis=1,inplace=True)"
      ],
      "metadata": {
        "id": "mmRVpOKjuDR6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Missing Values & Missing Value Imputation\n",
        "df.isnull().any()"
      ],
      "metadata": {
        "id": "iRsAHk1K0fpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "I already dealed with the null values during EDA Process"
      ],
      "metadata": {
        "id": "9QfZf7DmtSAd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### 2. Handling Outliers"
      ],
      "metadata": {
        "id": "id1riN9m0vUs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Checking outliers\n",
        "continous_col=['release_year','duration','added_year','added_month','added_day']\n",
        "for col in continous_col:\n",
        "  sns.boxplot(data[col])\n",
        "  plt.title(f'{col} BoxPlot')\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "lioHaK_3umGB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we can see that there are some outliers present but every data is important so i will not remove them from my data"
      ],
      "metadata": {
        "id": "U21C_1140mKz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Categorical Encoding"
      ],
      "metadata": {
        "id": "89xtkJwZ18nB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode your categorical columns"
      ],
      "metadata": {
        "id": "21JmIYMG2hEo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What all categorical encoding techniques have you used & why did you use those techniques?"
      ],
      "metadata": {
        "id": "67NQN5KX2AMe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "UDaue5h32n_G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Textual Data Preprocessing\n",
        "(It's mandatory for textual dataset i.e., NLP, Sentiment Analysis, Text Clustering etc.)"
      ],
      "metadata": {
        "id": "Iwf50b-R2tYG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Expand Contraction"
      ],
      "metadata": {
        "id": "GMQiZwjn3iu7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "id": "K80znu6l77GL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# creating new feature filtered\n",
        "df['filtered']=df['cast']+' '+df['director']+' '+df['type']+' '+df['country']+' '+df['description']+' '+df['listed_in']+' '+df['rating']\n",
        "df.head()"
      ],
      "metadata": {
        "id": "PTouz10C3oNN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Lower Casing"
      ],
      "metadata": {
        "id": "WVIkgGqN3qsr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lower Casing\n",
        "df['filtered']=df['filtered'].str.lower()\n",
        "#After lower casing the filtered column\n",
        "df['filtered'][0]"
      ],
      "metadata": {
        "id": "88JnJ1jN3w7j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we have lower cased the particular column"
      ],
      "metadata": {
        "id": "l4akQ_Nd0-0Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Removing Punctuations"
      ],
      "metadata": {
        "id": "XkPnILGE3zoT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove Punctuations\n",
        "import string\n",
        "print('I am going to remove these Punctuations from the Column',string.punctuation)"
      ],
      "metadata": {
        "id": "vqbBqNaA33c0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#storing punctuations in exclude\n",
        "exclude=string.punctuation\n",
        "#defining function that will remove punctuation\n",
        "def remove_punc(text):\n",
        "  return text.translate(str.maketrans('','',exclude))\n",
        "#applying on filtered column\n",
        "df['filtered']=df['filtered'].apply(remove_punc)"
      ],
      "metadata": {
        "id": "8bL1sf2R1msA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#after removing punctuation\n",
        "df['filtered'][0]"
      ],
      "metadata": {
        "id": "j73wksS-3XxI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Removing of punctuations is important because on tokenization each punctuation are going to considered as a separate word which increase dimensionality or they can be combined with any  word cause to change the meaning of that particular word"
      ],
      "metadata": {
        "id": "2LY9-c5B3jDa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4. Removing URLs & Removing words and digits contain digits."
      ],
      "metadata": {
        "id": "Hlsf0x5436Go"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove URLs & Remove words and digits contain digits\n",
        "import re\n",
        "import string\n",
        "# defining function to remove URLs/number from the 'filtered' column\n",
        "def remove_url(text):\n",
        "  pattern=re.compile(r'https?://\\S+|www\\.\\S+')\n",
        "  text= re.sub(pattern,'', text)\n",
        "  # Replacing the number digit with space\n",
        "  text = re.sub('[^a-zA-Z]', ' ', text)\n",
        "  # return the text that doesn't contain any URL's or Numbers\n",
        "  return text\n",
        "#Applying function on Column\n",
        "df['filtered']=df['filtered'].apply(remove_url)"
      ],
      "metadata": {
        "id": "2sxKgKxu4Ip3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 5. Removing Stopwords & Removing White spaces"
      ],
      "metadata": {
        "id": "mT9DMSJo4nBL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove Stopwords\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "# Downloading stop words\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Getting the set of English stopwords\n",
        "stop_words = set(stopwords.words('english'))\n",
        "print('These are the stop words:',stop_words)\n",
        "\n",
        "# Remove stopwords from the 'filtered' column\n",
        "df['filtered'] = df['filtered'].apply(lambda x: ' '.join(word for word in x.split() if word.lower() not in stop_words))\n"
      ],
      "metadata": {
        "id": "T2LSJh154s8W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#checking column after removing stop words\n",
        "df['filtered'][0]"
      ],
      "metadata": {
        "id": "f168lDe4PIlK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Stops words are only used for the formation of sentence."
      ],
      "metadata": {
        "id": "h9fNBrVBBSaa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 7. Tokenization"
      ],
      "metadata": {
        "id": "OeJFEK0N496M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenization\n",
        "from nltk.tokenize import word_tokenize\n",
        "# Download NLTK resources\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Tokenize function\n",
        "def tokenize_text(text):\n",
        "    return word_tokenize(text)\n",
        "\n",
        "# Apply tokenization on the 'filtered' column\n",
        "df['filtered'] = df['filtered'].apply(tokenize_text)\n"
      ],
      "metadata": {
        "id": "ijx1rUOS5CUU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#checking column after applying tokenization\n",
        "df['filtered'][0]"
      ],
      "metadata": {
        "id": "1OAFvSYWEQOb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tokenization is the process of breaking text document into smaller parts called **Tokens** which can be word/sentence/phrase based on requirement"
      ],
      "metadata": {
        "id": "YcN_aS_gEzB6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 8. Text Normalization"
      ],
      "metadata": {
        "id": "9ExmJH0g5HBk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import WordNetLemmatizer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "#Downloading needed resource\n",
        "nltk.download('wordnet')\n",
        "\n",
        "\n",
        "# Initialize lemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "# Apply lemmatization on the  column\n",
        "df['filtered'] = df['filtered'].apply(lambda x: [lemmatizer.lemmatize(word) for word in x])\n"
      ],
      "metadata": {
        "id": "AIJ1a-Zc5PY8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which text normalization technique have you used and why?"
      ],
      "metadata": {
        "id": "cJNqERVU536h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I have used **Lemmatization** instead of stemming as it helps to reduce inflected words properly ensuring that root word belongs to the language and it checks the value from WordNetLemmatizer dictonary and gives accurate results"
      ],
      "metadata": {
        "id": "Z9jKVxE06BC1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 9. Part of speech tagging"
      ],
      "metadata": {
        "id": "k5UmGsbsOxih"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# POS Taging\n",
        "# Download the necessary resources for POS tagging\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "# Apply POS tagging on the filtered column\n",
        "df['pos_tags'] = df['filtered'].apply(lambda x: nltk.pos_tag(x))\n"
      ],
      "metadata": {
        "id": "btT3ZJBAO6Ik"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#checking column after applying Pos Tagging\n",
        "df['pos_tags'][0]"
      ],
      "metadata": {
        "id": "5uLCfI779kmV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 10. Text Vectorization"
      ],
      "metadata": {
        "id": "T0VqWOYE6DLQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Vectorizing Text\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Convert the list of lists to a list of strings\n",
        "filtered_text = [' '.join(tokens) for tokens in df['filtered']]\n",
        "\n",
        "# Create an instance of TfidfVectorizer\n",
        "tfidf = TfidfVectorizer(max_features=15000)\n",
        "\n",
        "# Fitting TfidfVectorizer\n",
        "x = tfidf.fit_transform(filtered_text)\n",
        "print(x.shape)"
      ],
      "metadata": {
        "id": "yBRtdhth6JDE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which text vectorization technique have you used and why?"
      ],
      "metadata": {
        "id": "qBMux9mC6MCf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I have used TfidVectorizer as it doesn't give equal weightage to each text/token but instead it calculated Term frequency and Inverse Document Frequency and gives importance based on tf*idf value.It gives more importance to words that are frequently used in document and rare in corpus of words."
      ],
      "metadata": {
        "id": "su2EnbCh6UKQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7. Dimesionality Reduction"
      ],
      "metadata": {
        "id": "1UUpS68QDMuG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Do you think that dimensionality reduction is needed? Explain Why?"
      ],
      "metadata": {
        "id": "kexQrXU-DjzY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have 15000 features in our sparse matrix which is huge number so i am using PCA for reducing dimensionality"
      ],
      "metadata": {
        "id": "GGRlBsSGDtTQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# DImensionality Reduction\n",
        "#import labrary\n",
        "from sklearn.decomposition import PCA\n",
        "pca=PCA()\n",
        "\n",
        "#fitting PCA\n",
        "pca.fit(x.toarray())"
      ],
      "metadata": {
        "id": "kQfvxBBHDvCa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#plotting of variance captures vs number of components\n",
        "variance = pca.explained_variance_ratio_\n",
        "plt.plot(np.cumsum(variance))\n",
        "plt.xlabel('number of components')\n",
        "plt.ylabel('Percent of variance captured')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "pHVB-EjsJyxm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now here we can see that around 7750 components captures 100% variance.Now i am going to consider those number of components who can capture around 95% of variance"
      ],
      "metadata": {
        "id": "9EkAJHoELlL1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Now passing the argument that can capture 95% of variance.\n",
        "pca= PCA(n_components=0.95)\n",
        "\n",
        "# Fitting and transforming the model\n",
        "pca.fit(x.toarray())\n",
        "x_transformed = pca.transform(x.toarray())\n",
        "\n",
        "# Checking the shape of transformed matrix\n",
        "x_transformed.shape"
      ],
      "metadata": {
        "id": "U_VZuU0GK3_T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we got **5289** PCA Components that explains around **95%** of variance"
      ],
      "metadata": {
        "id": "Z6sKoXq8A3xn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which dimensionality reduction technique have you used and why? (If dimensionality reduction done on dataset.)"
      ],
      "metadata": {
        "id": "T5CmagL3EC8N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I have used **Principal Component Analysis** (PCA) for reducing the dimensionality of my input data while capturing 95% of the variance.The input data contain **15000** features and by using PCA it got reduced to **5289** which explains 95% of the variance.\n",
        "\n",
        "PCA helps in reducing the dimensionality of the data by projecting it onto a lower-dimensional space while preserving the most important features (capturing most of the variance)."
      ],
      "metadata": {
        "id": "ZKr75IDuEM7t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***7. ML Model Implementation***"
      ],
      "metadata": {
        "id": "VfCC591jGiD4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 1 K Means Clustering"
      ],
      "metadata": {
        "id": "OB4l2ZhMeS1U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#using Elbow curve Method to find out optimal number of cluster\n",
        "#Importing necessay libraries\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "# Define a range of values for k\n",
        "k_values = range(2, 21)\n",
        "\n",
        "# Initialize an empty list to store the WCSS values(within cluster sum of square)\n",
        "wcss = []\n",
        "\n",
        "# Iterate over each value of k\n",
        "for k in k_values:\n",
        "    # Fit the KMeans algorithm\n",
        "    km = KMeans(n_clusters=k, random_state=1)\n",
        "    km.fit(x_transformed)\n",
        "\n",
        "    # Calculate the within-cluster sum of squares\n",
        "    wcss.append(km.inertia_)\n",
        "\n",
        "# Plot the elbow curve\n",
        "plt.plot(k_values, wcss, 'bo-')\n",
        "plt.xlabel('Number of Clusters (k)')\n",
        "plt.ylabel('Within-Cluster Sum of Squares (WCSS)')\n",
        "plt.title('Elbow Curve')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "72ChsT2pWUqZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "from the plot 10 can be consider as optimal number of cluster.Before proceding futher let's use **SSlhouette Score** to find optinal number of cluster"
      ],
      "metadata": {
        "id": "42lOXDMZbtnb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_score\n",
        "\n",
        "# Define a range of values for k\n",
        "k_values = range(2, 21)\n",
        "\n",
        "# Initialize an empty list to store the silhouette scores\n",
        "silhouette_scores = []\n",
        "\n",
        "# Iterate over each value of k\n",
        "for k in k_values:\n",
        "    # Fit the KMeans algorithm\n",
        "    km = KMeans(n_clusters=k, random_state=1)\n",
        "    km.fit(x_transformed)\n",
        "\n",
        "    # Calculate the silhouette score\n",
        "    silhouette_scores.append(silhouette_score(x_transformed, km.labels_))\n",
        "# Plot the Silhouette scores\n",
        "plt.plot(k_values, silhouette_scores, 'bo-')\n",
        "plt.xlabel('Number of Clusters (k)')\n",
        "plt.ylabel('Silhouette Score')\n",
        "plt.title('Silhouette Score for Different Numbers of Clusters')\n",
        "plt.show()\n",
        "# Find the optimal number of clusters with the highest silhouette score\n",
        "optimal_k = k_values[silhouette_scores.index(max(silhouette_scores))]\n",
        "\n",
        "# Print the optimal number of clusters\n",
        "print(\"Optimal number of clusters:\", optimal_k)\n"
      ],
      "metadata": {
        "id": "pAwwk0uZcUVu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Sihouette score gives us the measurement of how close each sample in one cluster and far from neighbouring cluster.It takes into account both the cohesion (similarity within a cluster) and the separation (dissimilarity between clusters) of the data points.Sihouette score ranges from (-1 to 1),a higher Silhouette score indicates better-defined and well-matched clusters, while a lower score suggests overlapping or poorly matched clusters\n",
        "\n",
        "from the plot it can been seen that optimal number of cluster is 5"
      ],
      "metadata": {
        "id": "Te3YGoA5kNyr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the K-means model on the dataset\n",
        "kmeans = KMeans(n_clusters=5, init='k-means++', random_state=0)\n",
        "\n",
        "# Predict the labels of clusters\n",
        "labels = kmeans.fit_predict(x_transformed)\n",
        "\n",
        "# Getting unique labels\n",
        "unique_labels = np.unique(labels)\n",
        "\n",
        "# Plotting the results\n",
        "for i in unique_labels:\n",
        "    plt.scatter(x_transformed[labels == i, 0], x_transformed[labels == i, 1], label=i)\n",
        "\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "vIg2Fpjvl_st"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Visualizing the cluster in 3D\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "\n",
        "# Create a 3D plot\n",
        "fig = plt.figure(figsize=(10, 8))\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "\n",
        "# Plotting the results\n",
        "for i in unique_labels:\n",
        "    cluster_points = x_transformed[labels == i]\n",
        "    ax.scatter(cluster_points[:, 0], cluster_points[:, 1], cluster_points[:, 2], label=f'Cluster {i}')\n",
        "ax.legend()\n",
        "ax.set_xlabel('x-axis')\n",
        "ax.set_ylabel('y-axis')\n",
        "ax.set_zlabel('z-axis')\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "dMmRUyXtpYU2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Now label the dataset as per cluster\n",
        "df['kmeans_cluster']=kmeans.labels_\n",
        "#let's check dataset now\n",
        "df.head()"
      ],
      "metadata": {
        "id": "czmpaeoDruB3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[df['kmeans_cluster']==0]['title','director','cast','']"
      ],
      "metadata": {
        "id": "yYEYVXm69P-i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "ArJBuiUVfxKd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart"
      ],
      "metadata": {
        "id": "rqD5ZohzfxKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 2 Hierarchical Clustering"
      ],
      "metadata": {
        "id": "dJ2tPlVmpsJ0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's first plot Dendogram to find out optimal number of clusters"
      ],
      "metadata": {
        "id": "zJpZy-uNVNB8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#importing necessary labraries\n",
        "import scipy.cluster.hierarchy as sch\n",
        "\n",
        "# Plot the dendrogram\n",
        "plt.figure(figsize=(12, 6))\n",
        "dendrogram = sch.dendrogram(sch.linkage(x_transformed, method = 'ward'))\n",
        "plt.title('Dendrogram')\n",
        "plt.xlabel('Content')\n",
        "plt.ylabel('Euclidean Distances')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "EK5gRgUnTuYE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "from dendogram it can be seen optimal number of clusters is 2"
      ],
      "metadata": {
        "id": "_YMMa0ISkED1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import AgglomerativeClustering\n",
        "from sklearn.metrics import silhouette_score\n",
        "\n",
        "# Define a range of values for k\n",
        "k_values = range(2,10)\n",
        "\n",
        "# Initialize an empty list to store the silhouette scores\n",
        "silhouette_scores = []\n",
        "\n",
        "# Iterate over each value of k\n",
        "for k in k_values:\n",
        "    # Fit the KMeans algorithm\n",
        "    km = AgglomerativeClustering(n_clusters=k)\n",
        "    km.fit(x_transformed)\n",
        "\n",
        "    # Calculate the silhouette score\n",
        "    silhouette_scores.append(silhouette_score(x_transformed, km.labels_))\n",
        "# Plot the Silhouette scores\n",
        "plt.plot(k_values, silhouette_scores, 'bo-')\n",
        "plt.xlabel('Number of Clusters (k)')\n",
        "plt.ylabel('Silhouette Score')\n",
        "plt.title('Silhouette Score for Different Numbers of Clusters')\n",
        "plt.show()\n",
        "# Find the optimal number of clusters with the highest silhouette score\n",
        "optimal_k = k_values[silhouette_scores.index(max(silhouette_scores))]\n",
        "\n",
        "# Print the optimal number of clusters\n",
        "print(\"Optimal number of clusters:\", optimal_k)\n"
      ],
      "metadata": {
        "id": "q9r4m-2X9yWc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fitting Agglomerative clustering to the  dataset\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "hc = AgglomerativeClustering(n_clusters = 3, affinity = 'euclidean', linkage = 'ward')\n",
        "# Predict the labels of clusters\n",
        "labels = hc.fit_predict(x_transformed)\n",
        "\n",
        "# Getting unique labels\n",
        "unique_labels = np.unique(labels)\n",
        "\n",
        "# Plotting the results\n",
        "for i in unique_labels:\n",
        "    plt.scatter(x_transformed[labels == i, 0], x_transformed[labels == i, 1], label=i)\n",
        "\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "L4yKqsQvo_IN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here 2d clusters can be easily seen"
      ],
      "metadata": {
        "id": "47aTfAhJrx5S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Visualizing the cluster in 3D\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "\n",
        "# Create a 3D plot\n",
        "fig = plt.figure(figsize=(10, 8))\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "\n",
        "# Plotting the results\n",
        "for i in unique_labels:\n",
        "    cluster_points = x_transformed[labels == i]\n",
        "    ax.scatter(cluster_points[:, 0], cluster_points[:, 1], cluster_points[:, 2], label=f'Cluster {i}')\n",
        "ax.legend()\n",
        "ax.set_xlabel('x-axis')\n",
        "ax.set_ylabel('y-axis')\n",
        "ax.set_zlabel('z-axis')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ACS9caNuo5J7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Now label the dataset as per cluster\n",
        "df['aglomerative_clusters']=hc.labels_\n",
        "#let's check dataset now\n",
        "df.head()"
      ],
      "metadata": {
        "id": "efmvno-_rY-Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "JWYfwnehpsJ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart"
      ],
      "metadata": {
        "id": "yEl-hgQWpsJ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "-jK_YjpMpsJ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "\n",
        "# Fit the Algorithm\n",
        "\n",
        "# Predict on the model"
      ],
      "metadata": {
        "id": "Dn0EOfS6psJ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "HAih1iBOpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "9kBgjYcdpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "zVGeBEFhpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "74yRdG6UpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Explain each evaluation metric's indication towards business and the business impact pf the ML model used."
      ],
      "metadata": {
        "id": "bmKjuQ-FpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "BDKtOrBQpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 3"
      ],
      "metadata": {
        "id": "Fze-IPXLpx6K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 3 Implementation\n",
        "\n",
        "# Fit the Algorithm\n",
        "\n",
        "# Predict on the model"
      ],
      "metadata": {
        "id": "FFrSXAtrpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing neede libraries\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Create a TF-IDF vectorizer object and transform the text data\n",
        "tfidf = TfidfVectorizer(stop_words='english')\n",
        "tfidf_matrix = tfidf.fit_transform(df['filtered'])\n",
        "\n",
        "# Compute cosine similarity matrix\n",
        "cosine_sim = cosine_similarity(tfidf_matrix)\n",
        "\n",
        "def recommend_content(title, cosine_sim=cosine_sim, data=df):\n",
        "    # Get the index of the input title in the programme_list\n",
        "    programme_list = data['title'].to_list()\n",
        "    index = programme_list.index(title)\n",
        "\n",
        "    # Create a list of tuples containing the similarity score and index\n",
        "    # between the input title and all other programmes in the dataset\n",
        "    sim_scores = list(enumerate(cosine_sim[index]))\n",
        "\n",
        "    # Sort the list of tuples by similarity score in descending order\n",
        "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)[1:11]\n",
        "\n",
        "    # Get the recommended movie titles and their similarity scores\n",
        "    recommend_index = [i[0] for i in sim_scores]\n",
        "    rec_movie = data['title'].iloc[recommend_index]\n",
        "    rec_score = [round(i[1], 4) for i in sim_scores]\n",
        "\n",
        "    # Create a pandas DataFrame to display the recommendations\n",
        "    rec_table = pd.DataFrame(list(zip(rec_movie, rec_score)), columns=['Recommendation', 'Similarity_score(0-1)'])\n",
        "\n",
        "    return rec_table"
      ],
      "metadata": {
        "id": "dV9uCvncAqJK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "7AN1z2sKpx6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart"
      ],
      "metadata": {
        "id": "xIY4lxxGpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "9PIHJqyupx6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 3 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "\n",
        "# Fit the Algorithm\n",
        "\n",
        "# Predict on the model"
      ],
      "metadata": {
        "id": "eSVXuaSKpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "_-qAgymDpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "lQMffxkwpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "Z-hykwinpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "MzVzZC6opx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Which Evaluation metrics did you consider for a positive business impact and why?"
      ],
      "metadata": {
        "id": "h_CCil-SKHpo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "jHVz9hHDKFms"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Which ML model did you choose from the above created models as your final prediction model and why?"
      ],
      "metadata": {
        "id": "cBFFvTBNJzUa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "6ksF5Q1LKTVm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Explain the model which you have used and the feature importance using any model explainability tool?"
      ],
      "metadata": {
        "id": "HvGl1hHyA_VK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "YnvVTiIxBL-C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***8.*** ***Future Work (Optional)***"
      ],
      "metadata": {
        "id": "EyNgTHvd2WFk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Save the best performing ml model in a pickle file or joblib file format for deployment process.\n"
      ],
      "metadata": {
        "id": "KH5McJBi2d8v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the File"
      ],
      "metadata": {
        "id": "bQIANRl32f4J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Again Load the saved model file and try to predict unseen data for a sanity check.\n"
      ],
      "metadata": {
        "id": "iW_Lq9qf2h6X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the File and predict unseen data."
      ],
      "metadata": {
        "id": "oEXk9ydD2nVC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Congrats! Your model is successfully created and ready for deployment on a live server for a real user interaction !!!***"
      ],
      "metadata": {
        "id": "-Kee-DAl2viO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion**"
      ],
      "metadata": {
        "id": "gCX9965dhzqZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write the conclusion here."
      ],
      "metadata": {
        "id": "Fjb1IsQkh3yE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Hurrah! You have successfully completed your Machine Learning Capstone Project !!!***"
      ],
      "metadata": {
        "id": "gIfDvo9L0UH2"
      }
    }
  ]
}